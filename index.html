
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>arXiv 论文日报 2026-02-02</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #3498db; margin-top: 30px; }
        h3 { color: #2980b9; }
        p { line-height: 1.6; color: #34495e; }
        .topic-section { margin: 40px 0; padding: 20px; background: #f8f9fa; border-radius: 8px; }
        .paper-item { margin: 20px 0; padding: 15px; border: 1px solid #e0e0e0; border-radius: 4px; }
        .paper-title { font-size: 18px; font-weight: bold; color: #2980b9; }
        .paper-meta { color: #7f8c8d; font-size: 14px; margin: 5px 0; }
        .paper-summary { margin: 10px 0; line-height: 1.5; }
    </style>
</head>
<body>
    <h1>arXiv 论文日报 - 2026-02-02</h1>
    <div class="topic-section">
        <h2>arXiv 论文日报 2026-02-02</h2>
    </div>
    <div class="topic-section">
        <h2>RNA_structure_prediction</h2>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23286v1" target="_blank">VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23286v1</div>
            <div class="paper-meta"><strong>作者:</strong> Hongyang Du, Junjie Ye, Xiaoyan Cong, Runhao Li, Jingcheng Ni, Aman Agarwal, Zeqi Zhou, Zekun Li, Randall Balestriero, Yue Wang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:59</div>
            <div class="paper-meta"><strong>论文摘要:</strong> While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-efficient self-supervised framework that leverages a geometry foundation model to</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：视频扩散模型难以保持3D结构一致性；方法：引入VideoGPA，利用几何基础模型进行自监督学习；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23277v1" target="_blank">Understanding multiscale disorder in superconducting nanowire single photon detectors</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23277v1</div>
            <div class="paper-meta"><strong>作者:</strong> Nirjhar Sarkar, Ronan Gourgues, Yueh-Chun Wu, Chengyun Hua, Katyayani Seal, Andreas Fognini, Steven Randolph, Eugene Dumitrescu, Gabor B. Halasz, Benjamin Lawrie</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:48</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Superconducting nanowire single-photon detectors are central to applications across quantum information science. Yet, their performance is limited by the effects of disorder and electrodynamic inhomogeneities that are not well understood. By combining DC transport, dark-count measurements, and bias-dependent microwave transmission spectroscopy in the presence of controlled nanoscale disorder introduced through helium-ion irradiation, we distinguish local instability-driven processes from intrins</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：超导纳米线单光子探测器性能受限于无序和电磁不均匀性；方法：结合直流输运、暗计数测量和偏置微波传输光谱，引入氦离子辐照控制纳米级无序；结果：区分局部不稳定性驱动过程与内在机制。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23276v1" target="_blank">Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23276v1</div>
            <div class="paper-meta"><strong>作者:</strong> Shuhong Liu, Xining Ge, Ziying Gu, Lin Gu, Ziteng Cui, Xuangeng Chu, Jun Liu, Dong Li, Tatsuya Harada</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:47</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a physics-based noise synthesis framework tailored to CCD noise formation. The pipeline models photon</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：天文成像受噪声限制，标准校准无法有效去除随机噪声；方法：提出基于物理的CCD噪声合成框架，用于生成真实噪声数据；结果：提升学习去噪模型的训练效果与科学可解释性。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23273v1" target="_blank">UPA: Unsupervised Prompt Agent via Tree-Based Search and Selection</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23273v1</div>
            <div class="paper-meta"><strong>作者:</strong> Siran Peng, Weisong Zhao, Tianyu Fu, Chenxu Zhao, Tianshuo Zhang, Haoyuan Zhang, Xiangyu Zhu, Minghui Wu, Zhen Lei</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:39</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Prompt agents have recently emerged as a promising paradigm for automated prompt optimization, framing refinement as a sequential decision-making problem over a structured prompt space. While this formulation enables the use of advanced planning algorithms, these methods typically assume access to supervised reward signals, which are often unavailable in practical scenarios. In this work, we propose UPA, an Unsupervised Prompt Agent that realizes structured search and selection without relying o</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：传统Prompt代理依赖监督奖励信号，但实际场景中常不可用；方法：提出UPA，无需监督信号进行结构化搜索与选择；结果：实现有效的自动提示优化。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23272v1" target="_blank">Analytical topological invariants for 2D non-Hermitian phases using Morse theory</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23272v1</div>
            <div class="paper-meta"><strong>作者:</strong> Cameron Gibson, Evelyn Tang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:38</div>
            <div class="paper-meta"><strong>论文摘要:</strong> As energy dissipation and gain are ubiquitous in the real world, such phenomena demand the generalization of Hermitian methods such as the analysis of topological properties for non-Hermitian systems. However, as non-Hermitian systems typically contain more degrees of freedom, this poses a challenge for analytical approaches to understand their topology and invariants. In this work, we analytically calculate the 2D Zak phase for a 2D non-Hermitian SSH-type Hamiltonian that supports a rich struct</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：非厄米系统拓扑性质分析困难；方法：解析计算二维非厄米SSH模型的Zak相；结果：成功获得二维Zak相，为理解非厄米系统拓扑提供新途径。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23261v1" target="_blank">TEON: Tensorized Orthonormalization Beyond Layer-Wise Muon for Large Language Model Pre-Training</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23261v1</div>
            <div class="paper-meta"><strong>作者:</strong> Ruijie Zhang, Yequan Zhao, Ziyue Liu, Zhengyang Wang, Dongyang Li, Yupeng Su, Sijia Liu, Zheng Zhang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:30</div>
            <div class="paper-meta"><strong>论文摘要:</strong> The Muon optimizer has demonstrated strong empirical performance in pre-training large language models by performing matrix-level gradient (or momentum) orthogonalization in each layer independently. In this work, we propose TEON, a principled generalization of Muon that extends orthogonalization beyond individual layers by modeling the gradients of a neural network as a structured higher-order tensor. We present TEON's improved convergence guarantee over layer-wise Muon, and further develop a p</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：现有MuOn优化器仅在单层进行梯度正交化，可能限制性能；方法：提出TEON，将梯度建模为高阶张量进行全局正交化；结果：提供更优的收敛保证。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23257v1" target="_blank">Outcome-Conditioned Reasoning Distillation for Resolving Software Issues</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23257v1</div>
            <div class="paper-meta"><strong>作者:</strong> Chenglin Li, Yisen Xu, Zehao Wang, Shin Hwei Tan, Tse-Hsun, Chen</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:25</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Software issue resolution in large repositories is a long-range decision process: choices made during localization shape the space of viable edits, and missteps can compound into incorrect patches. Despite this, many LLM-based repair pipelines still operate in a reset-and-solve manner, producing fresh reasoning for every new issue instead of carrying forward what worked in past fixes. This is wasteful because repositories routinely contain earlier issues with overlapping structure, failure modes</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：大型代码库中的软件问题修复涉及长期决策，错误选择可能导致修复失败；方法：现有LLM修复流程多采用重置并解决的方式，未利用过往修复经验；结果：导致资源浪费，因相似问题重复处理。</div>
        </div>
    </div>
    <div class="topic-section">
        <h2>RNA_design</h2>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23280v1" target="_blank">Decoupled Diffusion Sampling for Inverse Problems on Function Spaces</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23280v1</div>
            <div class="paper-meta"><strong>作者:</strong> Thomas Y. L. Lin, Jiachen Yao, Lufang Chiang, Julius Berner, Anima Anandkumar</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:54</div>
            <div class="paper-meta"><strong>论文摘要:</strong> We propose a data-efficient, physics-aware generative framework in function space for inverse PDE problems. Existing plug-and-play diffusion posterior samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient prior, while a neural operator explicitly models the forward PDE for guidance. This dec</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：逆偏微分方程问题数据效率低；方法：DDIS框架解耦系数先验与前向PDE建模；结果：提升生成效率与物理一致性。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23278v1" target="_blank">FOCUS: DLLMs Know How to Tame Their Compute Bound</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23278v1</div>
            <div class="paper-meta"><strong>作者:</strong> Kaihua Liang, Xin Tan, An Zhong, Hong Xu, Marco Canini</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:52</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. We further observe a strong correlation between attention-derived token importance and token-wise dec</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：DLLM解码中存在计算浪费问题；方法：识别注意力机制中token重要性与可解码性相关性；结果：提出优化策略提升解码效率。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23271v1" target="_blank">Time-Resolved Interferometric Measurements of Plasma Density Evolution in Laser-Driven Capacitor-Coil Targets</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23271v1</div>
            <div class="paper-meta"><strong>作者:</strong> Yang Zhang, Ryo Omura, Rinya Akematsu, King Fai Farley Law, Brandon K. Russell, Geoffrey Pomraning, Kian Orr, Kai Kimura, Muhammad Fauzan Syahbana, Yuga Karaki, Hiroki Matsubara, Ryuya Yamada, Jinyuan</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:37</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Laser-driven capacitor-coil targets provide a compact platform for generating strong magnetic fields and are widely used in magnetized high-energy-density plasma experiments. In addition to magnetic-field generation, these targets also produce plasma in the coil region, which can influence the subject physical processes, interact with secondary targets or external plasmas in their applications. However, direct, time-resolved measurements of the plasma density surrounding the coil remain limited.</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：激光驱动电容-线圈靶产生强磁场和等离子体，但缺乏对线圈周围等离子体密度的实时测量；方法：无；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23269v1" target="_blank">Rank Reduction AutoEncoders for Mechanical Design: Advancing Novel and Efficient Data-Driven Topology Optimization</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23269v1</div>
            <div class="paper-meta"><strong>作者:</strong> Ismael Ben-Yelun, Mohammed El Fallaki Idrissi, Jad Mounayer, Sebastian Rodriguez, Francisco Chinesta</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:36</div>
            <div class="paper-meta"><strong>论文摘要:</strong> This work presents a data-driven framework for fast forward and inverse analysis in topology optimization (TO) by combining Rank Reduction Autoencoders (RRAEs) with neural latent-space mappings. The methodology targets the efficient approximation of the relationship between optimized geometries and their corresponding mechanical responses or Quantity of Interest (QoI), with a particular focus on compliance-minimized linear elastic structures. High-dimensional TO results are first compressed usin</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：拓扑优化中快速正向与逆向分析；方法：结合降秩自编码器与神经潜在空间映射的数据驱动框架；结果：高效近似几何结构与力学响应间的关系。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23268v1" target="_blank">TCBench: A Benchmark for Tropical Cyclone Track and Intensity Forecasting at the Global Scale</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23268v1</div>
            <div class="paper-meta"><strong>作者:</strong> Milton Gomez, Marie McGraw, Saranya Ganesh S., Frederick Iat-Hin Tam, Ilia Azizi, Samuel Darmon, Monika Feldmann, Stella Bourdin, Louis Poulain--Auzéau, Suzana J. Camargo, Jonathan Lin, Dan Chavas, Ch</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:34</div>
            <div class="paper-meta"><strong>论文摘要:</strong> TCBench is a benchmark for evaluating global, short to medium-range (1-5 days) forecasts of tropical cyclone (TC) track and intensity. To allow a fair and model-agnostic comparison, TCBench builds on the IBTrACS observational dataset and formulates TC forecasting as predicting the time evolution of an existing tropical system conditioned on its initial position and intensity. TCBench includes state-of-the-art dynamical (TIGGE) and neural weather models (AIFS, Pangu-Weather, FourCastNet v2, GenCa</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：评估热带气旋轨迹和强度的短期至中期预测；方法：基于IBTrACS数据，将TC预测建模为初始状态条件下的时间演化问题；结果：包含多种先进动力和神经天气模型的基准测试。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23255v1" target="_blank">Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23255v1</div>
            <div class="paper-meta"><strong>作者:</strong> Ye Yu, Haibo Jin, Yaoning Yu, Jun Zhuang, Haohan Wang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:23</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds disallowed directives within a narrative-style audio stream. The attack leverages an advanced instru</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：语音输入大模型存在安全漏洞；方法：设计文本转音频越狱攻击，将违规指令嵌入叙述性音频流中；结果：揭示了语音模态下的新型安全风险。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23243v1" target="_blank">Complete Hierarchies for the Geometric Measure of Entanglement</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23243v1</div>
            <div class="paper-meta"><strong>作者:</strong> Lisa T. Weinbrenner, Albert Rico, Kenneth Goodenough, Xiao-Dong Yu, Otfried Gühne</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:12</div>
            <div class="paper-meta"><strong>论文摘要:</strong> In quantum physics, multiparticle systems are described by quantum states acting on tensor products of Hilbert spaces. This product structure leads to the distinction between product states and entangled states; moreover, one can quantify entanglement by considering the distance of a quantum state to the set of product states. The underlying optimization problem occurs frequently in physics and beyond, for instance in the computation of the injective tensor norm in multilinear algebra. Here, we</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：量子多粒子系统中如何量化纠缠；方法：通过计算量子态与乘积态集的距离；结果：该优化问题在物理和多线性代数中广泛应用。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23239v1" target="_blank">Graph Attention Network for Node Regression on Random Geometric Graphs with Erdős--Rényi contamination</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23239v1</div>
            <div class="paper-meta"><strong>作者:</strong> Somak Laha, Suqi Liu, Morgane Austern</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:09</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Graph attention networks (GATs) are widely used and often appear robust to noise in node covariates and edges, yet rigorous statistical guarantees demonstrating a provable advantage of GATs over non-attention graph neural networks~(GNNs) are scarce. We partially address this gap for node regression with graph-based errors-in-variables models under simultaneous covariate and edge corruption: responses are generated from latent node-level covariates, but only noise-perturbed versions of the latent</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：GATs在节点回归中对协变量和边的噪声是否具有统计优势缺乏理论证明；方法：基于图误差模型分析GATs与非注意力GNN的性能差异；结果：GATs在同时存在协变量和边扰动时表现更优。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23238v1" target="_blank">How well do generative models solve inverse problems? A benchmark study</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23238v1</div>
            <div class="paper-meta"><strong>作者:</strong> Patrick Krüger, Patrick Materne, Werner Krebs, Hanno Gottschalk</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:06</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Generative learning generates high dimensional data based on low dimensional conditions, also called prompts. Therefore, generative learning algorithms are eligible for solving (Bayesian) inverse problems. In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a prior sampled with the Markov Chain Monte Carlo method with three state of the art generative learning models, namely conditional Generative Adversarial Networks, Invertible Neural Netw</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：生成学习用于解决贝叶斯逆问题；方法：对比传统贝叶斯方法与三种生成模型（条件GAN、可逆神经网络等）；结果：生成模型在高维数据生成中表现更优。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2601.23236v1" target="_blank">YuriiFormer: A Suite of Nesterov-Accelerated Transformers</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2601.23236v1</div>
            <div class="paper-meta"><strong>作者:</strong> Aleksandr Zimin, Yury Polyanskiy, Philippe Rigollet</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-01-30 18:06</div>
            <div class="paper-meta"><strong>论文摘要:</strong> We propose a variational framework that interprets transformer layers as iterations of an optimization algorithm acting on token embeddings. In this view, self-attention implements a gradient step of an interaction energy, while MLP layers correspond to gradient updates of a potential energy. Standard GPT-style transformers emerge as vanilla gradient descent on the resulting composite objective, implemented via Lie--Trotter splitting between these two energy functionals. This perspective enables</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：如何从优化角度解释Transformer结构；方法：将自注意力视为交互能量的梯度步，MLP视为势能梯度更新；结果：标准Transformer可视为复合目标的梯度下降。</div>
        </div>
    </div>

</body>
</html>
