
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>arXiv 论文日报 2026-02-06</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 1200px; margin: 0 auto; padding: 20px; }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #3498db; margin-top: 30px; }
        h3 { color: #2980b9; }
        p { line-height: 1.6; color: #34495e; }
        .topic-section { margin: 40px 0; padding: 20px; background: #f8f9fa; border-radius: 8px; }
        .paper-item { margin: 20px 0; padding: 15px; border: 1px solid #e0e0e0; border-radius: 4px; }
        .paper-title { font-size: 18px; font-weight: bold; color: #2980b9; }
        .paper-meta { color: #7f8c8d; font-size: 14px; margin: 5px 0; }
        .paper-summary { margin: 10px 0; line-height: 1.5; }
    </style>
</head>
<body>
    <h1>arXiv 论文日报 - 2026-02-06</h1>
    <div class="topic-section">
        <h2>arXiv 论文日报 2026-02-06</h2>
    </div>
    <div class="topic-section">
        <h2>RNA_structure_prediction</h2>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06037v1" target="_blank">Thinking with Geometry: Active Geometry Integration for Spatial Reasoning</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06037v1</div>
            <div class="paper-meta"><strong>作者:</strong> Haoyuan Li, Qihang Cao, Tao Tang, Kun Xiang, Zihan Guo, Jianhua Han, Hang Xu, Xiaodan Liang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:59</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Recent progress in spatial reasoning with Multimodal Large Language Models (MLLMs) increasingly leverages geometric priors from 3D encoders. However, most existing integration strategies remain passive: geometry is exposed as a global stream and fused in an indiscriminate manner, which often induces semantic-geometry misalignment and redundant signals. We propose GeoThinker, a framework that shifts the paradigm from passive fusion to active perception. Instead of feature mixing, GeoThinker enabl</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：现有MLLM在空间推理中几何信息融合存在语义-几何错位和冗余；方法：提出GeoThinker，通过主动感知替代被动融合；结果：提升空间推理性能。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06028v1" target="_blank">Context Forcing: Consistent Autoregressive Video Generation with Long Context</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06028v1</div>
            <div class="paper-meta"><strong>作者:</strong> Shuo Chen, Cong Wei, Sun Sun, Ping Nie, Kai Zhou, Ge Zhang, Ming-Hsuan Yang, Wenhu Chen</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:58</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Recent approaches to real-time long video generation typically employ streaming tuning strategies, attempting to train a long-context student using a short-context (memoryless) teacher. In these frameworks, the student performs long rollouts but receives supervision from a teacher limited to short 5-second windows. This structural discrepancy creates a critical \textbf{student-teacher mismatch}: the teacher's inability to access long-term history prevents it from guiding the student on global te</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：实时长视频生成中存在学生-教师不匹配问题；方法：使用短时教师监督长时学生；结果：教师无法提供全局指导导致性能受限。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06027v1" target="_blank">ACT DR6+Planck impact on inflation with non-zero vacuum expectation value and the post-inflationary behavior</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06027v1</div>
            <div class="paper-meta"><strong>作者:</strong> F. B. M. dos Santos, J. G. Rodrigues, G. Rodrigues, C. Siqueira, J. S. Alcaniz</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:57</div>
            <div class="paper-meta"><strong>论文摘要:</strong> The impact of the most recent cosmic microwave background (CMB) data from the Atacama Cosmology Telescope (ACT) is studied for a model of cosmic inflation which predicts a non-zero vacuum expectation value (VEV) $M$ for a large-field regime. Since lower values of $M$ are compatible with the higher spectral index $n_s$ provided by the ACT+Planck joint analysis, we establish new limits on this parameter while also considering further CMB data from the latest BICEP/Keck Array release for CMB polari</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：研究ACT最新CMB数据对大场宇宙暴胀模型中真空期望值M的影响；方法：结合ACT+Planck和BICEP/Keck Array的CMB数据进行分析；结果：得出新的M参数限制，低M值与高谱指数ns兼容。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06025v1" target="_blank">Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06025v1</div>
            <div class="paper-meta"><strong>作者:</strong> Haozhen Zhang, Haodong Yue, Tao Feng, Quanyu Long, Jianzhu Bao, Bowen Jin, Weizhi Zhang, Xiao Li, Jiaxuan You, Chengwei Qin, Wenya Wang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:57</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control over the performance-cost trade-off. In this work, we present \textbf{BudgetMem}, a runtime agent mem</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：LLM代理在超出单个上下文窗口时面临内存效率和信息保留的挑战；方法：提出BudgetMem，一种运行时内存管理机制；结果：有效控制性能与成本的权衡，提升内存利用效率。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06020v1" target="_blank">Mechanisms of AI Protein Folding in ESMFold</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06020v1</div>
            <div class="paper-meta"><strong>作者:</strong> Kevin Lu, Jannik Brinkmann, Stefan Huber, Aaron Mueller, Yonatan Belinkov, David Bau, Chris Wendler</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:54</div>
            <div class="paper-meta"><strong>论文摘要:</strong> How do protein structure prediction models fold proteins? We investigate this question by tracing how ESMFold folds a beta hairpin, a prevalent structural motif. Through counterfactual interventions on model latents, we identify two computational stages in the folding trunk. In the first stage, early blocks initialize pairwise biochemical signals: residue identities and associated biochemical features such as charge flow from sequence representations into pairwise representations. In the second</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：蛋白质结构预测模型如何折叠蛋白质？；方法：通过追踪ESMFold折叠β发夹结构，进行反事实干预分析；结果：发现折叠过程包含两个计算阶段，早期块初始化成对生化信号。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06016v1" target="_blank">Convex unions and completions from simplicial pseudomanifolds</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06016v1</div>
            <div class="paper-meta"><strong>作者:</strong> Soohyun Park</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:53</div>
            <div class="paper-meta"><strong>论文摘要:</strong> While intersections of convex sets are convex, their unions have rather complicated behavior. Some natural contexts where they appear include duality arguments involving boundaries of convex sets and valuations, which have an Euler characteristic-like structure. However, there are certain settings where the convexity property itself is important to consider. For example, this includes (preservation of) positivity properties of divisors on toric varieties under blowdowns. In the case of (restrict</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：凸集的并集行为复杂，某些情况下需关注凸性；方法：研究凸集并集在对偶、指标理论及 торic 变量中的性质；结果：在特定情境下，如除子在爆破下的正性保持，凸性仍具重要性。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06015v1" target="_blank">A Systematic Evaluation of Large Language Models for PTSD Severity Estimation: The Role of Contextual Knowledge and Modeling Strategies</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06015v1</div>
            <div class="paper-meta"><strong>作者:</strong> Panagiotis Kaliosis, Adithya V Ganesan, Oscar N. E. Kjell, Whitney Ringwald, Scott Feltman, Melissa A. Carr, Dimitris Samaras, Camilo Ruggero, Benjamin J. Luft, Roman Kotov, Andrew H. Schwartz</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:53</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Large language models (LLMs) are increasingly being used in a zero-shot fashion to assess mental health conditions, yet we have limited knowledge on what factors affect their accuracy. In this study, we utilize a clinical dataset of natural language narratives and self-reported PTSD severity scores from 1,437 individuals to comprehensively evaluate the performance of 11 state-of-the-art LLMs. To understand the factors affecting accuracy, we systematically varied (i) contextual knowledge like sub</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：评估大语言模型在零样本情况下对PTSD评估的准确性及其影响因素；方法：使用1437人的临床数据集，测试11个先进LLM的性能，并系统变化上下文知识等变量；结果：发现上下文知识显著影响模型准确性。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06011v1" target="_blank">Excursion decomposition of the XOR-Ising model</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06011v1</div>
            <div class="paper-meta"><strong>作者:</strong> Tomás Alcalde López, Avelio Sepúlveda</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:51</div>
            <div class="paper-meta"><strong>论文摘要:</strong> We study the excursion decomposition of the two-dimensional critical XOR-Ising model with either $+$ or free boundary conditions. In the first part, we construct the decomposition directly in the continuum. This construction relies on the identification of the XOR-Ising field with the cosine or sine of a Gaussian free field (GFF) $φ$ multiplied by $α= 1/\sqrt{2}$, and is obtained by an appropriate exploration of two-valued level sets of the GFF. More generally, the same construction applies to t</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：二维临界XOR-Ising模型的遍历分解；方法：利用高斯自由场（GFF）的余弦或正弦构造分解；结果：通过探索GFF的双值水平集实现分解。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06009v1" target="_blank">Characterizing and Modeling the GitHub Security Advisories Review Pipeline</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06009v1</div>
            <div class="paper-meta"><strong>作者:</strong> Claudio Segal, Paulo Segal, Carlos Eduardo de Schuller Banjar, Felipe Paixão, Hudson Silva Borges, Paulo Silveira Neto, Eduardo Santana de Almeida, Joanna C. S. Santos, Anton Kocheturov, Gaurav Kumar</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:50</div>
            <div class="paper-meta"><strong>论文摘要:</strong> GitHub Security Advisories (GHSA) have become a central component of open-source vulnerability disclosure and are widely used by developers and security tools. A distinctive feature of GHSA is that only a fraction of advisories are reviewed by GitHub, while the mechanisms associated with this review process remain poorly understood. In this paper, we conduct a large-scale empirical study of GHSA review processes, analyzing over 288,000 advisories spanning 2019--2025. We characterize which adviso</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：GitHub Security Advisories（GHSA）的审核机制不明确，部分 advisories 未被审核；方法：分析2019-2025年间28.8万条 GHSA 数据，研究审核特征；结果：发现审核率低，且审核与漏洞严重性、发布者身份等因素相关。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06008v1" target="_blank">AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06008v1</div>
            <div class="paper-meta"><strong>作者:</strong> Xianyang Liu, Shangding Gu, Dawn Song</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:50</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models markets in which buyers and sellers possess private constraints and product-dependent valuations, and must</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：缺乏评估多智能体语言经济交互的基准；方法：引入AgenticPay，模拟买家卖家自然语言谈判；结果：构建了包含私有约束和产品估值的市场模型。</div>
        </div>
    </div>
    <div class="topic-section">
        <h2>RNA_design</h2>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06042v1" target="_blank">Pseudo-Invertible Neural Networks</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06042v1</div>
            <div class="paper-meta"><strong>作者:</strong> Yamit Ehrlich, Nimrod Berman, Assaf Shocher</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:59</div>
            <div class="paper-meta"><strong>论文摘要:</strong> The Moore-Penrose Pseudo-inverse (PInv) serves as the fundamental solution for linear systems. In this paper, we propose a natural generalization of PInv to the nonlinear regime in general and to neural networks in particular. We introduce Surjective Pseudo-invertible Neural Networks (SPNN), a class of architectures explicitly designed to admit a tractable non-linear PInv. The proposed non-linear PInv and its implementation in SPNN satisfy fundamental geometric properties. One such property is n</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：传统伪逆方法无法处理非线性系统；方法：提出SPNN架构实现非线性伪逆；结果：满足基本几何性质。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06040v1" target="_blank">SwimBird: Eliciting Switchable Reasoning Mode in Hybrid Autoregressive MLLMs</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06040v1</div>
            <div class="paper-meta"><strong>作者:</strong> Jintao Tong, Shilin Yan, Hongwei Xue, Xiaojun Tang, Kunyu Shi, Guannan Zhang, Ruixuan Li, Yixiong Zou</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:59</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Multimodal Large Language Models (MLLMs) have made remarkable progress in multimodal perception and reasoning by bridging vision and language. However, most existing MLLMs perform reasoning primarily with textual CoT, which limits their effectiveness on vision-intensive tasks. Recent approaches inject a fixed number of continuous hidden states as "visual thoughts" into the reasoning process and improve visual performance, but often at the cost of degraded text-based logical reasoning. We argue t</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：现有多模态大语言模型在视觉密集型任务中表现受限，依赖文本思维链导致视觉推理效果不足；方法：引入固定数量的连续隐藏状态作为“视觉思维”提升视觉性能；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06038v1" target="_blank">CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06038v1</div>
            <div class="paper-meta"><strong>作者:</strong> Xiaopan Zhang, Zejin Wang, Zhixu Li, Jianpeng Yao, Jiachen Li</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:59</div>
            <div class="paper-meta"><strong>论文摘要:</strong> To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, effective information gathering is important in completing these assignments. To address this compone</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：多机器人协作完成人类自然语言指令的任务；方法：结合指令理解、场景问答和目标物体操作；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06029v1" target="_blank">Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06029v1</div>
            <div class="paper-meta"><strong>作者:</strong> Yingke Li, Anjali Parashar, Enlu Zhou, Chuchu Fan</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:58</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertainty resolution, while excessive curiosity can induce unnecessary exploration and regret. We establish</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：如何平衡主动推理中的好奇心以实现有效学习与决策；方法：通过调整好奇系数优化信息获取与任务表现的权衡；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06003v1" target="_blank">Modeling integrated frequency shifters and beam splitters</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06003v1</div>
            <div class="paper-meta"><strong>作者:</strong> Manuel H. Muñoz-Arias, Kevin J. Randles, Nils T. Otterstrom, Paul S. Davids, Michael Gehl, Mohan Sarovar</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:48</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Photonic quantum computing is a strong contender in the race to fault-tolerance. Recent proposals using qubits encoded in frequency modes promise a large reduction in hardware footprint, and have garnered much attention. In this encoding, linear optics, i.e., beam splitters and phase shifters, is necessarily not energy-conserving, and is costly to implement. In this work, we present designs of frequency-mode beam splitters based on modulated arrays of coupled resonators. We develop a methodology</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：频率模式光子量子计算中线性光学器件能耗高、成本高；方法：设计基于调制耦合谐振器阵列的频率模式分束器；结果：提出一种新型实现方法。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.06000v1" target="_blank">Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.06000v1</div>
            <div class="paper-meta"><strong>作者:</strong> Ali Shendabadi, Parnia Izadirad, Mostafa Salehi, Mahmoud Bijankhan</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:46</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, in speech emotion recognition by proposing two attention-based pooling methods, Multi-head Attentive Average Pooling and QKV Pooling, designed to efficiently reduce the dimensionality of Whisper rep</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：Speech Emotion Recognition 数据集不足，传统方法效果有限；方法：提出两种基于注意力的池化方法，利用 Whisper 提取特征；结果：有效降低维度并提升 SER 性能。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.05998v1" target="_blank">VisRefiner: Learning from Visual Differences for Screenshot-to-Code Generation</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.05998v1</div>
            <div class="paper-meta"><strong>作者:</strong> Jie Deng, Kaichun Yao, Libo Zhang</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:45</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Screenshot-to-code generation aims to translate user interface screenshots into executable frontend code that faithfully reproduces the target layout and style. Existing multimodal large language models perform this mapping directly from screenshots but are trained without observing the visual outcomes of their generated code. In contrast, human developers iteratively render their implementation, compare it with the design, and learn how visual differences relate to code changes. Inspired by thi</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：从截图生成代码的准确性不足；方法：借鉴人类开发者通过渲染和对比迭代优化代码的过程；结果：无。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.05997v1" target="_blank">Causal Inference on Stopped Random Walks in Online Advertising</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.05997v1</div>
            <div class="paper-meta"><strong>作者:</strong> Jia Yuan Yu</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:43</div>
            <div class="paper-meta"><strong>论文摘要:</strong> We consider a causal inference problem frequently encountered in online advertising systems, where a publisher (e.g., Instagram, TikTok) interacts repeatedly with human users and advertisers by sporadically displaying to each user an advertisement selected through an auction. Each treatment corresponds to a parameter value of the advertising mechanism (e.g., auction reserve-price), and we want to estimate through experiments the corresponding long-term treatment effect (e.g., annual advertising</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：在线广告系统中，估计广告机制参数的长期处理效应；方法：通过实验设计和因果推断方法分析广告展示策略的影响；结果：提出一种有效评估广告机制长期效果的框架。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.05996v1" target="_blank">Orthogonal Self-Attention</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.05996v1</div>
            <div class="paper-meta"><strong>作者:</strong> Leo Zhang, James Martens</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:42</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Softmax Self-Attention (SSA) is a key component of Transformer architectures. However, when utilised within skipless architectures, which aim to improve representation learning, recent work has highlighted the inherent instability of SSA due to inducing rank collapse and poorly-conditioned Jacobians. In this work, we design a novel attention mechanism: Orthogonal Self-Attention (OSA), which aims to bypass these issues with SSA, in order to allow for (non-causal) Transformers without skip connect</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：Transformer中Softmax Self-Attention在无跳跃连接架构中存在稳定性问题；方法：设计Orthogonal Self-Attention机制；结果：解决Rank Collapse和Jacobian条件差问题。</div>
        </div>
        <div class="paper-item">
            <div class="paper-title"><a href="http://arxiv.org/abs/2602.05993v1" target="_blank">Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps</a></div>
            <div class="paper-meta"><strong>arXiv ID:</strong> 2602.05993v1</div>
            <div class="paper-meta"><strong>作者:</strong> Peter Holderrieth, Douglas Chen, Luca Eyring, Ishin Shah, Giri Anantharaman, Yutong He, Zeynep Akata, Tommi Jaakkola, Nicholas Matthew Boffi, Max Simchowitz</div>
            <div class="paper-meta"><strong>更新时间:</strong> 2026-02-05 18:42</div>
            <div class="paper-meta"><strong>论文摘要:</strong> Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an afterthought, and redesign the model for adaptability. We propose "Diamond Maps", stochastic flow map models that enable efficient and accurate alignment to arbitrary rewards at inference time. Diamond</div>
            <div class="paper-meta"><strong>核心总结:</strong> 问题：生成模型在训练后难以高效适应用户偏好或约束；方法：提出Diamond Maps，一种可高效对齐任意奖励的随机流映射模型；结果：实现推理时的高效准确奖励对齐。</div>
        </div>
    </div>

</body>
</html>
